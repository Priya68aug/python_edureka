{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "names = ['sepal-name', 'sepal-width','petal-length', 'petal-width', 'class']\n",
    "dataset = pandas.read_csv(url, names = names )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-name</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-name  sepal-width  petal-length  petal-width           class\n",
       "0           5.1          3.5           1.4          0.2     Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2     Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2     Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2     Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2     Iris-setosa\n",
       "..          ...          ...           ...          ...             ...\n",
       "145         6.7          3.0           5.2          2.3  Iris-virginica\n",
       "146         6.3          2.5           5.0          1.9  Iris-virginica\n",
       "147         6.5          3.0           5.2          2.0  Iris-virginica\n",
       "148         6.2          3.4           5.4          2.3  Iris-virginica\n",
       "149         5.9          3.0           5.1          1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5)\n"
     ]
    }
   ],
   "source": [
    "print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-name</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal-name  sepal-width  petal-length  petal-width        class\n",
       "0          5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1          4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2          4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3          4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4          5.0          3.6           1.4          0.2  Iris-setosa\n",
       "5          5.4          3.9           1.7          0.4  Iris-setosa\n",
       "6          4.6          3.4           1.4          0.3  Iris-setosa\n",
       "7          5.0          3.4           1.5          0.2  Iris-setosa\n",
       "8          4.4          2.9           1.4          0.2  Iris-setosa\n",
       "9          4.9          3.1           1.5          0.1  Iris-setosa\n",
       "10         5.4          3.7           1.5          0.2  Iris-setosa\n",
       "11         4.8          3.4           1.6          0.2  Iris-setosa\n",
       "12         4.8          3.0           1.4          0.1  Iris-setosa\n",
       "13         4.3          3.0           1.1          0.1  Iris-setosa\n",
       "14         5.8          4.0           1.2          0.2  Iris-setosa\n",
       "15         5.7          4.4           1.5          0.4  Iris-setosa\n",
       "16         5.4          3.9           1.3          0.4  Iris-setosa\n",
       "17         5.1          3.5           1.4          0.3  Iris-setosa\n",
       "18         5.7          3.8           1.7          0.3  Iris-setosa\n",
       "19         5.1          3.8           1.5          0.3  Iris-setosa\n",
       "20         5.4          3.4           1.7          0.2  Iris-setosa\n",
       "21         5.1          3.7           1.5          0.4  Iris-setosa\n",
       "22         4.6          3.6           1.0          0.2  Iris-setosa\n",
       "23         5.1          3.3           1.7          0.5  Iris-setosa\n",
       "24         4.8          3.4           1.9          0.2  Iris-setosa\n",
       "25         5.0          3.0           1.6          0.2  Iris-setosa\n",
       "26         5.0          3.4           1.6          0.4  Iris-setosa\n",
       "27         5.2          3.5           1.5          0.2  Iris-setosa\n",
       "28         5.2          3.4           1.4          0.2  Iris-setosa\n",
       "29         4.7          3.2           1.6          0.2  Iris-setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-name</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal-name  sepal-width  petal-length  petal-width\n",
       "count  150.000000   150.000000    150.000000   150.000000\n",
       "mean     5.843333     3.054000      3.758667     1.198667\n",
       "std      0.828066     0.433594      1.764420     0.763161\n",
       "min      4.300000     2.000000      1.000000     0.100000\n",
       "25%      5.100000     2.800000      1.600000     0.300000\n",
       "50%      5.800000     3.000000      4.350000     1.300000\n",
       "75%      6.400000     3.300000      5.100000     1.800000\n",
       "max      7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('class').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.plot(kind = 'box', subplots = True, layout=(2,2), sharex = False, sharey = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter_matrix(dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = dataset.values\n",
    "X = array[:,0:4]\n",
    "y = array[:,4]\n",
    "validation_size = 0.20\n",
    "seed = 6\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size= validation_size, random_state = seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR:  0.950000  (0.076376)\n",
      "LDA:  0.975000  (0.038188)\n",
      "KNN:  0.958333  (0.055902)\n",
      "CART:  0.950000  (0.040825)\n",
      "NB:  0.966667  (0.055277)\n",
      "SVM:  0.950000  (0.076376)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n",
      "C:\\Users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "models = [ ]\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC()))\n",
    "\n",
    "#evaluate each model in turn\n",
    "results = [ ]\n",
    "names = [ ]\n",
    "\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state= seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train, y_train, cv = kfold)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    msg = \"%s:  %f  (%f)\"  %  (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package sklearn.model_selection in sklearn:\n",
      "\n",
      "NAME\n",
      "    sklearn.model_selection\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _search\n",
      "    _split\n",
      "    _validation\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        sklearn.model_selection._search.ParameterGrid\n",
      "        sklearn.model_selection._search.ParameterSampler\n",
      "        sklearn.model_selection._split.BaseCrossValidator\n",
      "            sklearn.model_selection._split.LeaveOneGroupOut\n",
      "            sklearn.model_selection._split.LeaveOneOut\n",
      "            sklearn.model_selection._split.LeavePGroupsOut\n",
      "            sklearn.model_selection._split.LeavePOut\n",
      "            sklearn.model_selection._split.PredefinedSplit\n",
      "    sklearn.model_selection._search.BaseSearchCV(sklearn.base.MetaEstimatorMixin, sklearn.base.BaseEstimator)\n",
      "        sklearn.model_selection._search.GridSearchCV\n",
      "        sklearn.model_selection._search.RandomizedSearchCV\n",
      "    sklearn.model_selection._split.BaseShuffleSplit(builtins.object)\n",
      "        sklearn.model_selection._split.ShuffleSplit\n",
      "            sklearn.model_selection._split.GroupShuffleSplit\n",
      "        sklearn.model_selection._split.StratifiedShuffleSplit\n",
      "    sklearn.model_selection._split._BaseKFold(sklearn.model_selection._split.BaseCrossValidator)\n",
      "        sklearn.model_selection._split.GroupKFold\n",
      "        sklearn.model_selection._split.KFold\n",
      "        sklearn.model_selection._split.StratifiedKFold\n",
      "        sklearn.model_selection._split.TimeSeriesSplit\n",
      "    sklearn.model_selection._split._RepeatedSplits(builtins.object)\n",
      "        sklearn.model_selection._split.RepeatedKFold\n",
      "        sklearn.model_selection._split.RepeatedStratifiedKFold\n",
      "    \n",
      "    class BaseCrossValidator(builtins.object)\n",
      "     |  Base class for all cross-validators\n",
      "     |  \n",
      "     |  Implementations must define `_iter_test_masks` or `_iter_test_indices`.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset({'get_n_splits'})\n",
      "    \n",
      "    class GridSearchCV(BaseSearchCV)\n",
      "     |  GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      "     |  \n",
      "     |  Exhaustive search over specified parameter values for an estimator.\n",
      "     |  \n",
      "     |  Important members are fit, predict.\n",
      "     |  \n",
      "     |  GridSearchCV implements a \"fit\" and a \"score\" method.\n",
      "     |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      "     |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      "     |  estimator used.\n",
      "     |  \n",
      "     |  The parameters of the estimator used to apply these methods are optimized\n",
      "     |  by cross-validated grid-search over a parameter grid.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <grid_search>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  estimator : estimator object.\n",
      "     |      This is assumed to implement the scikit-learn estimator interface.\n",
      "     |      Either estimator needs to provide a ``score`` function,\n",
      "     |      or ``scoring`` must be passed.\n",
      "     |  \n",
      "     |  param_grid : dict or list of dictionaries\n",
      "     |      Dictionary with parameters names (`str`) as keys and lists of\n",
      "     |      parameter settings to try as values, or a list of such\n",
      "     |      dictionaries, in which case the grids spanned by each dictionary\n",
      "     |      in the list are explored. This enables searching over any sequence\n",
      "     |      of parameter settings.\n",
      "     |  \n",
      "     |  scoring : str, callable, list/tuple or dict, default=None\n",
      "     |      A single str (see :ref:`scoring_parameter`) or a callable\n",
      "     |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "     |  \n",
      "     |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      "     |      or a dict with names as keys and callables as values.\n",
      "     |  \n",
      "     |      NOTE that when using custom scorers, each scorer should return a single\n",
      "     |      value. Metric functions returning a list/array of values can be wrapped\n",
      "     |      into multiple scorers that return one value each.\n",
      "     |  \n",
      "     |      See :ref:`multimetric_grid_search` for an example.\n",
      "     |  \n",
      "     |      If None, the estimator's score method is used.\n",
      "     |  \n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of jobs to run in parallel.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |  \n",
      "     |      .. versionchanged:: v0.20\n",
      "     |         `n_jobs` default changed from 1 to None\n",
      "     |  \n",
      "     |  pre_dispatch : int, or str, default=n_jobs\n",
      "     |      Controls the number of jobs that get dispatched during parallel\n",
      "     |      execution. Reducing this number can be useful to avoid an\n",
      "     |      explosion of memory consumption when more jobs get dispatched\n",
      "     |      than CPUs can process. This parameter can be:\n",
      "     |  \n",
      "     |          - None, in which case all the jobs are immediately\n",
      "     |            created and spawned. Use this for lightweight and\n",
      "     |            fast-running jobs, to avoid delays due to on-demand\n",
      "     |            spawning of the jobs\n",
      "     |  \n",
      "     |          - An int, giving the exact number of total jobs that are\n",
      "     |            spawned\n",
      "     |  \n",
      "     |          - A str, giving an expression as a function of n_jobs,\n",
      "     |            as in '2*n_jobs'\n",
      "     |  \n",
      "     |  iid : bool, default=False\n",
      "     |      If True, return the average score across folds, weighted by the number\n",
      "     |      of samples in each test set. In this case, the data is assumed to be\n",
      "     |      identically distributed across the folds, and the loss minimized is\n",
      "     |      the total loss per sample, and not the mean loss across the folds.\n",
      "     |  \n",
      "     |      .. deprecated:: 0.22\n",
      "     |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      "     |  \n",
      "     |  cv : int, cross-validation generator or an iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |  \n",
      "     |      - None, to use the default 5-fold cross validation,\n",
      "     |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |  \n",
      "     |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "     |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "     |      other cases, :class:`KFold` is used.\n",
      "     |  \n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |  \n",
      "     |  refit : bool, str, or callable, default=True\n",
      "     |      Refit an estimator using the best found parameters on the whole\n",
      "     |      dataset.\n",
      "     |  \n",
      "     |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      "     |      scorer that would be used to find the best parameters for refitting\n",
      "     |      the estimator at the end.\n",
      "     |  \n",
      "     |      Where there are considerations other than maximum score in\n",
      "     |      choosing a best estimator, ``refit`` can be set to a function which\n",
      "     |      returns the selected ``best_index_`` given ``cv_results_``. In that\n",
      "     |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      "     |      according to the returned ``best_index_`` while the ``best_score_``\n",
      "     |      attribute will not be available.\n",
      "     |  \n",
      "     |      The refitted estimator is made available at the ``best_estimator_``\n",
      "     |      attribute and permits using ``predict`` directly on this\n",
      "     |      ``GridSearchCV`` instance.\n",
      "     |  \n",
      "     |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      "     |      ``best_score_`` and ``best_params_`` will only be available if\n",
      "     |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      "     |      scorer.\n",
      "     |  \n",
      "     |      See ``scoring`` parameter to know more about multiple metric\n",
      "     |      evaluation.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.20\n",
      "     |          Support for callable added.\n",
      "     |  \n",
      "     |  verbose : integer\n",
      "     |      Controls the verbosity: the higher, the more messages.\n",
      "     |  \n",
      "     |  error_score : 'raise' or numeric, default=np.nan\n",
      "     |      Value to assign to the score if an error occurs in estimator fitting.\n",
      "     |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      "     |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      "     |      step, which will always raise the error.\n",
      "     |  \n",
      "     |  return_train_score : bool, default=False\n",
      "     |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      "     |      scores.\n",
      "     |      Computing training scores is used to get insights on how different\n",
      "     |      parameter settings impact the overfitting/underfitting trade-off.\n",
      "     |      However computing the scores on the training set can be computationally\n",
      "     |      expensive and is not strictly required to select the parameters that\n",
      "     |      yield the best generalization performance.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.19\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.21\n",
      "     |          Default value was changed from ``True`` to ``False``\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn import svm, datasets\n",
      "     |  >>> from sklearn.model_selection import GridSearchCV\n",
      "     |  >>> iris = datasets.load_iris()\n",
      "     |  >>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
      "     |  >>> svc = svm.SVC()\n",
      "     |  >>> clf = GridSearchCV(svc, parameters)\n",
      "     |  >>> clf.fit(iris.data, iris.target)\n",
      "     |  GridSearchCV(estimator=SVC(),\n",
      "     |               param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      "     |  >>> sorted(clf.cv_results_.keys())\n",
      "     |  ['mean_fit_time', 'mean_score_time', 'mean_test_score',...\n",
      "     |   'param_C', 'param_kernel', 'params',...\n",
      "     |   'rank_test_score', 'split0_test_score',...\n",
      "     |   'split2_test_score', ...\n",
      "     |   'std_fit_time', 'std_score_time', 'std_test_score']\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  cv_results_ : dict of numpy (masked) ndarrays\n",
      "     |      A dict with keys as column headers and values as columns, that can be\n",
      "     |      imported into a pandas ``DataFrame``.\n",
      "     |  \n",
      "     |      For instance the below given table\n",
      "     |  \n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |      |param_kernel|param_gamma|param_degree|split0_test_score|...|rank_t...|\n",
      "     |      +============+===========+============+=================+===+=========+\n",
      "     |      |  'poly'    |     --    |      2     |       0.80      |...|    2    |\n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |      |  'poly'    |     --    |      3     |       0.70      |...|    4    |\n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |      |  'rbf'     |     0.1   |     --     |       0.80      |...|    3    |\n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |      |  'rbf'     |     0.2   |     --     |       0.93      |...|    1    |\n",
      "     |      +------------+-----------+------------+-----------------+---+---------+\n",
      "     |  \n",
      "     |      will be represented by a ``cv_results_`` dict of::\n",
      "     |  \n",
      "     |          {\n",
      "     |          'param_kernel': masked_array(data = ['poly', 'poly', 'rbf', 'rbf'],\n",
      "     |                                       mask = [False False False False]...)\n",
      "     |          'param_gamma': masked_array(data = [-- -- 0.1 0.2],\n",
      "     |                                      mask = [ True  True False False]...),\n",
      "     |          'param_degree': masked_array(data = [2.0 3.0 -- --],\n",
      "     |                                       mask = [False False  True  True]...),\n",
      "     |          'split0_test_score'  : [0.80, 0.70, 0.80, 0.93],\n",
      "     |          'split1_test_score'  : [0.82, 0.50, 0.70, 0.78],\n",
      "     |          'mean_test_score'    : [0.81, 0.60, 0.75, 0.85],\n",
      "     |          'std_test_score'     : [0.01, 0.10, 0.05, 0.08],\n",
      "     |          'rank_test_score'    : [2, 4, 3, 1],\n",
      "     |          'split0_train_score' : [0.80, 0.92, 0.70, 0.93],\n",
      "     |          'split1_train_score' : [0.82, 0.55, 0.70, 0.87],\n",
      "     |          'mean_train_score'   : [0.81, 0.74, 0.70, 0.90],\n",
      "     |          'std_train_score'    : [0.01, 0.19, 0.00, 0.03],\n",
      "     |          'mean_fit_time'      : [0.73, 0.63, 0.43, 0.49],\n",
      "     |          'std_fit_time'       : [0.01, 0.02, 0.01, 0.01],\n",
      "     |          'mean_score_time'    : [0.01, 0.06, 0.04, 0.04],\n",
      "     |          'std_score_time'     : [0.00, 0.00, 0.00, 0.01],\n",
      "     |          'params'             : [{'kernel': 'poly', 'degree': 2}, ...],\n",
      "     |          }\n",
      "     |  \n",
      "     |      NOTE\n",
      "     |  \n",
      "     |      The key ``'params'`` is used to store a list of parameter\n",
      "     |      settings dicts for all the parameter candidates.\n",
      "     |  \n",
      "     |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      "     |      ``std_score_time`` are all in seconds.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, the scores for all the scorers are\n",
      "     |      available in the ``cv_results_`` dict at the keys ending with that\n",
      "     |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      "     |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      "     |  \n",
      "     |  best_estimator_ : estimator\n",
      "     |      Estimator that was chosen by the search, i.e. estimator\n",
      "     |      which gave highest score (or smallest loss if specified)\n",
      "     |      on the left out data. Not available if ``refit=False``.\n",
      "     |  \n",
      "     |      See ``refit`` parameter for more information on allowed values.\n",
      "     |  \n",
      "     |  best_score_ : float\n",
      "     |      Mean cross-validated score of the best_estimator\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |      This attribute is not available if ``refit`` is a function.\n",
      "     |  \n",
      "     |  best_params_ : dict\n",
      "     |      Parameter setting that gave the best results on the hold out data.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  best_index_ : int\n",
      "     |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      "     |      candidate parameter setting.\n",
      "     |  \n",
      "     |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      "     |      the parameter setting for the best model, that gives the highest\n",
      "     |      mean score (``search.best_score_``).\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is present only if ``refit`` is\n",
      "     |      specified.\n",
      "     |  \n",
      "     |  scorer_ : function or a dict\n",
      "     |      Scorer function used on the held out data to choose the best\n",
      "     |      parameters for the model.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this attribute holds the validated\n",
      "     |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      "     |  \n",
      "     |  n_splits_ : int\n",
      "     |      The number of cross-validation splits (folds/iterations).\n",
      "     |  \n",
      "     |  refit_time_ : float\n",
      "     |      Seconds used for refitting the best model on the whole dataset.\n",
      "     |  \n",
      "     |      This is present only if ``refit`` is not False.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.20\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The parameters selected are those that maximize the score of the left out\n",
      "     |  data, unless an explicit score is passed in which case it is used instead.\n",
      "     |  \n",
      "     |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "     |  point in the grid (and not `n_jobs` times). This is done for efficiency\n",
      "     |  reasons if individual jobs take very little time, but may raise errors if\n",
      "     |  the dataset is large and not enough memory is available.  A workaround in\n",
      "     |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "     |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "     |  n_jobs`.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  ---------\n",
      "     |  :class:`ParameterGrid`:\n",
      "     |      generates all the combinations of a hyperparameter grid.\n",
      "     |  \n",
      "     |  :func:`sklearn.model_selection.train_test_split`:\n",
      "     |      utility function to split the data into a development set usable\n",
      "     |      for fitting a GridSearchCV instance and an evaluation set for\n",
      "     |      its final evaluation.\n",
      "     |  \n",
      "     |  :func:`sklearn.metrics.make_scorer`:\n",
      "     |      Make a scorer from a performance metric or loss function.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GridSearchCV\n",
      "     |      BaseSearchCV\n",
      "     |      sklearn.base.MetaEstimatorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, estimator, param_grid, *, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSearchCV:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Call decision_function on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``decision_function``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      "     |      Run fit with all sets of parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training vector, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "     |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      "     |      \n",
      "     |      **fit_params : dict of str -> object\n",
      "     |          Parameters passed to the ``fit`` method of the estimator\n",
      "     |  \n",
      "     |  inverse_transform(self, Xt)\n",
      "     |      Call inverse_transform on the estimator with the best found params.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator implements\n",
      "     |      ``inverse_transform`` and ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Xt : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Call predict on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Call predict_log_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_log_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Call predict_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  score(self, X, y=None)\n",
      "     |      Returns the score on the given data, if the estimator has been refit.\n",
      "     |      \n",
      "     |      This uses the score defined by ``scoring`` where provided, and the\n",
      "     |      ``best_estimator_.score`` method otherwise.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input data, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Call transform on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator supports ``transform`` and\n",
      "     |      ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSearchCV:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Estimator instance.\n",
      "    \n",
      "    class GroupKFold(_BaseKFold)\n",
      "     |  GroupKFold(n_splits=5)\n",
      "     |  \n",
      "     |  K-fold iterator variant with non-overlapping groups.\n",
      "     |  \n",
      "     |  The same group will not appear in two different folds (the number of\n",
      "     |  distinct groups has to be at least equal to the number of folds).\n",
      "     |  \n",
      "     |  The folds are approximately balanced in the sense that the number of\n",
      "     |  distinct groups is approximately the same in each fold.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``n_splits`` default value changed from 3 to 5.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import GroupKFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
      "     |  >>> y = np.array([1, 2, 3, 4])\n",
      "     |  >>> groups = np.array([0, 0, 2, 2])\n",
      "     |  >>> group_kfold = GroupKFold(n_splits=2)\n",
      "     |  >>> group_kfold.get_n_splits(X, y, groups)\n",
      "     |  2\n",
      "     |  >>> print(group_kfold)\n",
      "     |  GroupKFold(n_splits=2)\n",
      "     |  >>> for train_index, test_index in group_kfold.split(X, y, groups):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...     print(X_train, X_test, y_train, y_test)\n",
      "     |  ...\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  [[1 2]\n",
      "     |   [3 4]] [[5 6]\n",
      "     |   [7 8]] [1 2] [3 4]\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  [[5 6]\n",
      "     |   [7 8]] [[1 2]\n",
      "     |   [3 4]] [3 4] [1 2]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  LeaveOneGroupOut\n",
      "     |      For splitting the data according to explicit domain-specific\n",
      "     |      stratification of the dataset.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupKFold\n",
      "     |      _BaseKFold\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseKFold:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class GroupShuffleSplit(ShuffleSplit)\n",
      "     |  GroupShuffleSplit(n_splits=5, *, test_size=None, train_size=None, random_state=None)\n",
      "     |  \n",
      "     |  Shuffle-Group(s)-Out cross-validation iterator\n",
      "     |  \n",
      "     |  Provides randomized train/test indices to split data according to a\n",
      "     |  third-party provided group. This group information can be used to encode\n",
      "     |  arbitrary domain specific stratifications of the samples as integers.\n",
      "     |  \n",
      "     |  For instance the groups could be the year of collection of the samples\n",
      "     |  and thus allow for cross-validation against time-based splits.\n",
      "     |  \n",
      "     |  The difference between LeavePGroupsOut and GroupShuffleSplit is that\n",
      "     |  the former generates splits using all subsets of size ``p`` unique groups,\n",
      "     |  whereas GroupShuffleSplit generates a user-determined number of random\n",
      "     |  test splits, each with a user-determined fraction of unique groups.\n",
      "     |  \n",
      "     |  For example, a less computationally intensive alternative to\n",
      "     |  ``LeavePGroupsOut(p=10)`` would be\n",
      "     |  ``GroupShuffleSplit(test_size=10, n_splits=100)``.\n",
      "     |  \n",
      "     |  Note: The parameters ``test_size`` and ``train_size`` refer to groups, and\n",
      "     |  not to samples, as in ShuffleSplit.\n",
      "     |  \n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of re-shuffling & splitting iterations.\n",
      "     |  \n",
      "     |  test_size : float, int, default=0.2\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "     |      of groups to include in the test split (rounded up). If int,\n",
      "     |      represents the absolute number of test groups. If None, the value is\n",
      "     |      set to the complement of the train size.\n",
      "     |      The default will change in version 0.21. It will remain 0.2 only\n",
      "     |      if ``train_size`` is unspecified, otherwise it will complement\n",
      "     |      the specified ``train_size``.\n",
      "     |  \n",
      "     |  train_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the\n",
      "     |      proportion of the groups to include in the train split. If\n",
      "     |      int, represents the absolute number of train groups. If None,\n",
      "     |      the value is automatically set to the complement of the test size.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the randomness of the training and testing indices produced.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import GroupShuffleSplit\n",
      "     |  >>> X = np.ones(shape=(8, 2))\n",
      "     |  >>> y = np.ones(shape=(8, 1))\n",
      "     |  >>> groups = np.array([1, 1, 2, 2, 2, 3, 3, 3])\n",
      "     |  >>> print(groups.shape)\n",
      "     |  (8,)\n",
      "     |  >>> gss = GroupShuffleSplit(n_splits=2, train_size=.7, random_state=42)\n",
      "     |  >>> gss.get_n_splits()\n",
      "     |  2\n",
      "     |  >>> for train_idx, test_idx in gss.split(X, y, groups):\n",
      "     |  ...     print(\"TRAIN:\", train_idx, \"TEST:\", test_idx)\n",
      "     |  TRAIN: [2 3 4 5 6 7] TEST: [0 1]\n",
      "     |  TRAIN: [0 1 5 6 7] TEST: [2 3 4]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      GroupShuffleSplit\n",
      "     |      ShuffleSplit\n",
      "     |      BaseShuffleSplit\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5, *, test_size=None, train_size=None, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Randomized CV splitters may return different results for each call of\n",
      "     |      split. You can make the results identical by setting `random_state`\n",
      "     |      to an integer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class KFold(_BaseKFold)\n",
      "     |  KFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      "     |  \n",
      "     |  K-Folds cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets. Split\n",
      "     |  dataset into k consecutive folds (without shuffling by default).\n",
      "     |  \n",
      "     |  Each fold is then used once as a validation while the k - 1 remaining\n",
      "     |  folds form the training set.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``n_splits`` default value changed from 3 to 5.\n",
      "     |  \n",
      "     |  shuffle : bool, default=False\n",
      "     |      Whether to shuffle the data before splitting into batches.\n",
      "     |      Note that the samples within each split will not be shuffled.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      "     |      indices, which controls the randomness of each fold. Otherwise, this\n",
      "     |      parameter has no effect.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import KFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([1, 2, 3, 4])\n",
      "     |  >>> kf = KFold(n_splits=2)\n",
      "     |  >>> kf.get_n_splits(X)\n",
      "     |  2\n",
      "     |  >>> print(kf)\n",
      "     |  KFold(n_splits=2, random_state=None, shuffle=False)\n",
      "     |  >>> for train_index, test_index in kf.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The first ``n_samples % n_splits`` folds have size\n",
      "     |  ``n_samples // n_splits + 1``, other folds have size\n",
      "     |  ``n_samples // n_splits``, where ``n_samples`` is the number of samples.\n",
      "     |  \n",
      "     |  Randomized CV splitters may return different results for each call of\n",
      "     |  split. You can make the results identical by setting `random_state`\n",
      "     |  to an integer.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  StratifiedKFold\n",
      "     |      Takes group information into account to avoid building folds with\n",
      "     |      imbalanced class distributions (for binary or multiclass\n",
      "     |      classification tasks).\n",
      "     |  \n",
      "     |  GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
      "     |  \n",
      "     |  RepeatedKFold: Repeats K-Fold n times.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      KFold\n",
      "     |      _BaseKFold\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseKFold:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LeaveOneGroupOut(BaseCrossValidator)\n",
      "     |  Leave One Group Out cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data according to a third-party\n",
      "     |  provided group. This group information can be used to encode arbitrary\n",
      "     |  domain specific stratifications of the samples as integers.\n",
      "     |  \n",
      "     |  For instance the groups could be the year of collection of the samples\n",
      "     |  and thus allow for cross-validation against time-based splits.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import LeaveOneGroupOut\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
      "     |  >>> y = np.array([1, 2, 1, 2])\n",
      "     |  >>> groups = np.array([1, 1, 2, 2])\n",
      "     |  >>> logo = LeaveOneGroupOut()\n",
      "     |  >>> logo.get_n_splits(X, y, groups)\n",
      "     |  2\n",
      "     |  >>> logo.get_n_splits(groups=groups)  # 'groups' is always required\n",
      "     |  2\n",
      "     |  >>> print(logo)\n",
      "     |  LeaveOneGroupOut()\n",
      "     |  >>> for train_index, test_index in logo.split(X, y, groups):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...     print(X_train, X_test, y_train, y_test)\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  [[5 6]\n",
      "     |   [7 8]] [[1 2]\n",
      "     |   [3 4]] [1 2] [1 2]\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  [[1 2]\n",
      "     |   [3 4]] [[5 6]\n",
      "     |   [7 8]] [1 2] [1 2]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeaveOneGroupOut\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set. This 'groups' parameter must always be specified to\n",
      "     |          calculate the number of splits, though the other parameters can be\n",
      "     |          omitted.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LeaveOneOut(BaseCrossValidator)\n",
      "     |  Leave-One-Out cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets. Each\n",
      "     |  sample is used once as a test set (singleton) while the remaining\n",
      "     |  samples form the training set.\n",
      "     |  \n",
      "     |  Note: ``LeaveOneOut()`` is equivalent to ``KFold(n_splits=n)`` and\n",
      "     |  ``LeavePOut(p=1)`` where ``n`` is the number of samples.\n",
      "     |  \n",
      "     |  Due to the high number of test sets (which is the same as the\n",
      "     |  number of samples) this cross-validation method can be very costly.\n",
      "     |  For large datasets one should favor :class:`KFold`, :class:`ShuffleSplit`\n",
      "     |  or :class:`StratifiedKFold`.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import LeaveOneOut\n",
      "     |  >>> X = np.array([[1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([1, 2])\n",
      "     |  >>> loo = LeaveOneOut()\n",
      "     |  >>> loo.get_n_splits(X)\n",
      "     |  2\n",
      "     |  >>> print(loo)\n",
      "     |  LeaveOneOut()\n",
      "     |  >>> for train_index, test_index in loo.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...     print(X_train, X_test, y_train, y_test)\n",
      "     |  TRAIN: [1] TEST: [0]\n",
      "     |  [[3 4]] [[1 2]] [2] [1]\n",
      "     |  TRAIN: [0] TEST: [1]\n",
      "     |  [[1 2]] [[3 4]] [1] [2]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  LeaveOneGroupOut\n",
      "     |      For splitting the data according to explicit, domain-specific\n",
      "     |      stratification of the dataset.\n",
      "     |  \n",
      "     |  GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeaveOneOut\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  get_n_splits(self, X, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LeavePGroupsOut(BaseCrossValidator)\n",
      "     |  LeavePGroupsOut(n_groups)\n",
      "     |  \n",
      "     |  Leave P Group(s) Out cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data according to a third-party\n",
      "     |  provided group. This group information can be used to encode arbitrary\n",
      "     |  domain specific stratifications of the samples as integers.\n",
      "     |  \n",
      "     |  For instance the groups could be the year of collection of the samples\n",
      "     |  and thus allow for cross-validation against time-based splits.\n",
      "     |  \n",
      "     |  The difference between LeavePGroupsOut and LeaveOneGroupOut is that\n",
      "     |  the former builds the test sets with all the samples assigned to\n",
      "     |  ``p`` different values of the groups while the latter uses samples\n",
      "     |  all assigned the same groups.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_groups : int\n",
      "     |      Number of groups (``p``) to leave out in the test split.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import LeavePGroupsOut\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6]])\n",
      "     |  >>> y = np.array([1, 2, 1])\n",
      "     |  >>> groups = np.array([1, 2, 3])\n",
      "     |  >>> lpgo = LeavePGroupsOut(n_groups=2)\n",
      "     |  >>> lpgo.get_n_splits(X, y, groups)\n",
      "     |  3\n",
      "     |  >>> lpgo.get_n_splits(groups=groups)  # 'groups' is always required\n",
      "     |  3\n",
      "     |  >>> print(lpgo)\n",
      "     |  LeavePGroupsOut(n_groups=2)\n",
      "     |  >>> for train_index, test_index in lpgo.split(X, y, groups):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...     print(X_train, X_test, y_train, y_test)\n",
      "     |  TRAIN: [2] TEST: [0 1]\n",
      "     |  [[5 6]] [[1 2]\n",
      "     |   [3 4]] [1] [1 2]\n",
      "     |  TRAIN: [1] TEST: [0 2]\n",
      "     |  [[3 4]] [[1 2]\n",
      "     |   [5 6]] [2] [1 1]\n",
      "     |  TRAIN: [0] TEST: [1 2]\n",
      "     |  [[1 2]] [[3 4]\n",
      "     |   [5 6]] [1] [2 1]\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  GroupKFold: K-fold iterator variant with non-overlapping groups.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeavePGroupsOut\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_groups)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set. This 'groups' parameter must always be specified to\n",
      "     |          calculate the number of splits, though the other parameters can be\n",
      "     |          omitted.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,), default=None\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class LeavePOut(BaseCrossValidator)\n",
      "     |  LeavePOut(p)\n",
      "     |  \n",
      "     |  Leave-P-Out cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets. This results\n",
      "     |  in testing on all distinct samples of size p, while the remaining n - p\n",
      "     |  samples form the training set in each iteration.\n",
      "     |  \n",
      "     |  Note: ``LeavePOut(p)`` is NOT equivalent to\n",
      "     |  ``KFold(n_splits=n_samples // p)`` which creates non-overlapping test sets.\n",
      "     |  \n",
      "     |  Due to the high number of iterations which grows combinatorically with the\n",
      "     |  number of samples this cross-validation method can be very costly. For\n",
      "     |  large datasets one should favor :class:`KFold`, :class:`StratifiedKFold`\n",
      "     |  or :class:`ShuffleSplit`.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  p : int\n",
      "     |      Size of the test sets. Must be strictly less than the number of\n",
      "     |      samples.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import LeavePOut\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
      "     |  >>> y = np.array([1, 2, 3, 4])\n",
      "     |  >>> lpo = LeavePOut(2)\n",
      "     |  >>> lpo.get_n_splits(X)\n",
      "     |  6\n",
      "     |  >>> print(lpo)\n",
      "     |  LeavePOut(p=2)\n",
      "     |  >>> for train_index, test_index in lpo.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  TRAIN: [1 3] TEST: [0 2]\n",
      "     |  TRAIN: [1 2] TEST: [0 3]\n",
      "     |  TRAIN: [0 3] TEST: [1 2]\n",
      "     |  TRAIN: [0 2] TEST: [1 3]\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      LeavePOut\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, p)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_n_splits(self, X, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ParameterGrid(builtins.object)\n",
      "     |  ParameterGrid(param_grid)\n",
      "     |  \n",
      "     |  Grid of parameters with a discrete number of values for each.\n",
      "     |  \n",
      "     |  Can be used to iterate over parameter value combinations with the\n",
      "     |  Python built-in function iter.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <grid_search>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  param_grid : dict of str to sequence, or sequence of such\n",
      "     |      The parameter grid to explore, as a dictionary mapping estimator\n",
      "     |      parameters to sequences of allowed values.\n",
      "     |  \n",
      "     |      An empty dict signifies default parameters.\n",
      "     |  \n",
      "     |      A sequence of dicts signifies a sequence of grids to search, and is\n",
      "     |      useful to avoid exploring parameter combinations that make no sense\n",
      "     |      or have no effect. See the examples below.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.model_selection import ParameterGrid\n",
      "     |  >>> param_grid = {'a': [1, 2], 'b': [True, False]}\n",
      "     |  >>> list(ParameterGrid(param_grid)) == (\n",
      "     |  ...    [{'a': 1, 'b': True}, {'a': 1, 'b': False},\n",
      "     |  ...     {'a': 2, 'b': True}, {'a': 2, 'b': False}])\n",
      "     |  True\n",
      "     |  \n",
      "     |  >>> grid = [{'kernel': ['linear']}, {'kernel': ['rbf'], 'gamma': [1, 10]}]\n",
      "     |  >>> list(ParameterGrid(grid)) == [{'kernel': 'linear'},\n",
      "     |  ...                               {'kernel': 'rbf', 'gamma': 1},\n",
      "     |  ...                               {'kernel': 'rbf', 'gamma': 10}]\n",
      "     |  True\n",
      "     |  >>> ParameterGrid(grid)[1] == {'kernel': 'rbf', 'gamma': 1}\n",
      "     |  True\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  :class:`GridSearchCV`:\n",
      "     |      Uses :class:`ParameterGrid` to perform a full parallelized parameter\n",
      "     |      search.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getitem__(self, ind)\n",
      "     |      Get the parameters that would be ``ind``th in iteration\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ind : int\n",
      "     |          The iteration index\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : dict of str to any\n",
      "     |          Equal to list(self)[ind]\n",
      "     |  \n",
      "     |  __init__(self, param_grid)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |      Iterate over the points in the grid.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : iterator over dict of str to any\n",
      "     |          Yields dictionaries mapping each estimator parameter to one of its\n",
      "     |          allowed values.\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Number of points on the grid.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ParameterSampler(builtins.object)\n",
      "     |  ParameterSampler(param_distributions, n_iter, *, random_state=None)\n",
      "     |  \n",
      "     |  Generator on parameters sampled from given distributions.\n",
      "     |  \n",
      "     |  Non-deterministic iterable over random candidate combinations for hyper-\n",
      "     |  parameter search. If all parameters are presented as a list,\n",
      "     |  sampling without replacement is performed. If at least one parameter\n",
      "     |  is given as a distribution, sampling with replacement is used.\n",
      "     |  It is highly recommended to use continuous distributions for continuous\n",
      "     |  parameters.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <grid_search>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  param_distributions : dict\n",
      "     |      Dictionary with parameters names (`str`) as keys and distributions\n",
      "     |      or lists of parameters to try. Distributions must provide a ``rvs``\n",
      "     |      method for sampling (such as those from scipy.stats.distributions).\n",
      "     |      If a list is given, it is sampled uniformly.\n",
      "     |      If a list of dicts is given, first a dict is sampled uniformly, and\n",
      "     |      then a parameter is sampled using that dict as above.\n",
      "     |  \n",
      "     |  n_iter : integer\n",
      "     |      Number of parameter settings that are produced.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Pseudo random number generator state used for random uniform sampling\n",
      "     |      from lists of possible values instead of scipy.stats distributions.\n",
      "     |      Pass an int for reproducible output across multiple\n",
      "     |      function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Returns\n",
      "     |  -------\n",
      "     |  params : dict of str to any\n",
      "     |      **Yields** dictionaries mapping each estimator parameter to\n",
      "     |      as sampled value.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.model_selection import ParameterSampler\n",
      "     |  >>> from scipy.stats.distributions import expon\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> rng = np.random.RandomState(0)\n",
      "     |  >>> param_grid = {'a':[1, 2], 'b': expon()}\n",
      "     |  >>> param_list = list(ParameterSampler(param_grid, n_iter=4,\n",
      "     |  ...                                    random_state=rng))\n",
      "     |  >>> rounded_list = [dict((k, round(v, 6)) for (k, v) in d.items())\n",
      "     |  ...                 for d in param_list]\n",
      "     |  >>> rounded_list == [{'b': 0.89856, 'a': 1},\n",
      "     |  ...                  {'b': 0.923223, 'a': 1},\n",
      "     |  ...                  {'b': 1.878964, 'a': 2},\n",
      "     |  ...                  {'b': 1.038159, 'a': 2}]\n",
      "     |  True\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, param_distributions, n_iter, *, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __iter__(self)\n",
      "     |  \n",
      "     |  __len__(self)\n",
      "     |      Number of points that will be sampled.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class PredefinedSplit(BaseCrossValidator)\n",
      "     |  PredefinedSplit(test_fold)\n",
      "     |  \n",
      "     |  Predefined split cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data into train/test sets using a\n",
      "     |  predefined scheme specified by the user with the ``test_fold`` parameter.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  .. versionadded:: 0.16\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  test_fold : array-like of shape (n_samples,)\n",
      "     |      The entry ``test_fold[i]`` represents the index of the test set that\n",
      "     |      sample ``i`` belongs to. It is possible to exclude sample ``i`` from\n",
      "     |      any test set (i.e. include sample ``i`` in every training set) by\n",
      "     |      setting ``test_fold[i]`` equal to -1.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import PredefinedSplit\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> test_fold = [0, 1, -1, 1]\n",
      "     |  >>> ps = PredefinedSplit(test_fold)\n",
      "     |  >>> ps.get_n_splits()\n",
      "     |  2\n",
      "     |  >>> print(ps)\n",
      "     |  PredefinedSplit(test_fold=array([ 0,  1, -1,  1]))\n",
      "     |  >>> for train_index, test_index in ps.split():\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [1 2 3] TEST: [0]\n",
      "     |  TRAIN: [0 2] TEST: [1 3]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PredefinedSplit\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, test_fold)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X=None, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RandomizedSearchCV(BaseSearchCV)\n",
      "     |  RandomizedSearchCV(estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
      "     |  \n",
      "     |  Randomized search on hyper parameters.\n",
      "     |  \n",
      "     |  RandomizedSearchCV implements a \"fit\" and a \"score\" method.\n",
      "     |  It also implements \"predict\", \"predict_proba\", \"decision_function\",\n",
      "     |  \"transform\" and \"inverse_transform\" if they are implemented in the\n",
      "     |  estimator used.\n",
      "     |  \n",
      "     |  The parameters of the estimator used to apply these methods are optimized\n",
      "     |  by cross-validated search over parameter settings.\n",
      "     |  \n",
      "     |  In contrast to GridSearchCV, not all parameter values are tried out, but\n",
      "     |  rather a fixed number of parameter settings is sampled from the specified\n",
      "     |  distributions. The number of parameter settings that are tried is\n",
      "     |  given by n_iter.\n",
      "     |  \n",
      "     |  If all parameters are presented as a list,\n",
      "     |  sampling without replacement is performed. If at least one parameter\n",
      "     |  is given as a distribution, sampling with replacement is used.\n",
      "     |  It is highly recommended to use continuous distributions for continuous\n",
      "     |  parameters.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <randomized_parameter_search>`.\n",
      "     |  \n",
      "     |  .. versionadded:: 0.14\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  estimator : estimator object.\n",
      "     |      A object of that type is instantiated for each grid point.\n",
      "     |      This is assumed to implement the scikit-learn estimator interface.\n",
      "     |      Either estimator needs to provide a ``score`` function,\n",
      "     |      or ``scoring`` must be passed.\n",
      "     |  \n",
      "     |  param_distributions : dict or list of dicts\n",
      "     |      Dictionary with parameters names (`str`) as keys and distributions\n",
      "     |      or lists of parameters to try. Distributions must provide a ``rvs``\n",
      "     |      method for sampling (such as those from scipy.stats.distributions).\n",
      "     |      If a list is given, it is sampled uniformly.\n",
      "     |      If a list of dicts is given, first a dict is sampled uniformly, and\n",
      "     |      then a parameter is sampled using that dict as above.\n",
      "     |  \n",
      "     |  n_iter : int, default=10\n",
      "     |      Number of parameter settings that are sampled. n_iter trades\n",
      "     |      off runtime vs quality of the solution.\n",
      "     |  \n",
      "     |  scoring : str, callable, list/tuple or dict, default=None\n",
      "     |      A single str (see :ref:`scoring_parameter`) or a callable\n",
      "     |      (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "     |  \n",
      "     |      For evaluating multiple metrics, either give a list of (unique) strings\n",
      "     |      or a dict with names as keys and callables as values.\n",
      "     |  \n",
      "     |      NOTE that when using custom scorers, each scorer should return a single\n",
      "     |      value. Metric functions returning a list/array of values can be wrapped\n",
      "     |      into multiple scorers that return one value each.\n",
      "     |  \n",
      "     |      See :ref:`multimetric_grid_search` for an example.\n",
      "     |  \n",
      "     |      If None, the estimator's score method is used.\n",
      "     |  \n",
      "     |  n_jobs : int, default=None\n",
      "     |      Number of jobs to run in parallel.\n",
      "     |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "     |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "     |      for more details.\n",
      "     |  \n",
      "     |      .. versionchanged:: v0.20\n",
      "     |         `n_jobs` default changed from 1 to None\n",
      "     |  \n",
      "     |  pre_dispatch : int, or str, default=None\n",
      "     |      Controls the number of jobs that get dispatched during parallel\n",
      "     |      execution. Reducing this number can be useful to avoid an\n",
      "     |      explosion of memory consumption when more jobs get dispatched\n",
      "     |      than CPUs can process. This parameter can be:\n",
      "     |  \n",
      "     |          - None, in which case all the jobs are immediately\n",
      "     |            created and spawned. Use this for lightweight and\n",
      "     |            fast-running jobs, to avoid delays due to on-demand\n",
      "     |            spawning of the jobs\n",
      "     |  \n",
      "     |          - An int, giving the exact number of total jobs that are\n",
      "     |            spawned\n",
      "     |  \n",
      "     |          - A str, giving an expression as a function of n_jobs,\n",
      "     |            as in '2*n_jobs'\n",
      "     |  \n",
      "     |  iid : bool, default=False\n",
      "     |      If True, return the average score across folds, weighted by the number\n",
      "     |      of samples in each test set. In this case, the data is assumed to be\n",
      "     |      identically distributed across the folds, and the loss minimized is\n",
      "     |      the total loss per sample, and not the mean loss across the folds.\n",
      "     |  \n",
      "     |      .. deprecated:: 0.22\n",
      "     |          Parameter ``iid`` is deprecated in 0.22 and will be removed in 0.24\n",
      "     |  \n",
      "     |  cv : int, cross-validation generator or an iterable, default=None\n",
      "     |      Determines the cross-validation splitting strategy.\n",
      "     |      Possible inputs for cv are:\n",
      "     |  \n",
      "     |      - None, to use the default 5-fold cross validation,\n",
      "     |      - integer, to specify the number of folds in a `(Stratified)KFold`,\n",
      "     |      - :term:`CV splitter`,\n",
      "     |      - An iterable yielding (train, test) splits as arrays of indices.\n",
      "     |  \n",
      "     |      For integer/None inputs, if the estimator is a classifier and ``y`` is\n",
      "     |      either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "     |      other cases, :class:`KFold` is used.\n",
      "     |  \n",
      "     |      Refer :ref:`User Guide <cross_validation>` for the various\n",
      "     |      cross-validation strategies that can be used here.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "     |  \n",
      "     |  refit : bool, str, or callable, default=True\n",
      "     |      Refit an estimator using the best found parameters on the whole\n",
      "     |      dataset.\n",
      "     |  \n",
      "     |      For multiple metric evaluation, this needs to be a `str` denoting the\n",
      "     |      scorer that would be used to find the best parameters for refitting\n",
      "     |      the estimator at the end.\n",
      "     |  \n",
      "     |      Where there are considerations other than maximum score in\n",
      "     |      choosing a best estimator, ``refit`` can be set to a function which\n",
      "     |      returns the selected ``best_index_`` given the ``cv_results``. In that\n",
      "     |      case, the ``best_estimator_`` and ``best_params_`` will be set\n",
      "     |      according to the returned ``best_index_`` while the ``best_score_``\n",
      "     |      attribute will not be available.\n",
      "     |  \n",
      "     |      The refitted estimator is made available at the ``best_estimator_``\n",
      "     |      attribute and permits using ``predict`` directly on this\n",
      "     |      ``RandomizedSearchCV`` instance.\n",
      "     |  \n",
      "     |      Also for multiple metric evaluation, the attributes ``best_index_``,\n",
      "     |      ``best_score_`` and ``best_params_`` will only be available if\n",
      "     |      ``refit`` is set and all of them will be determined w.r.t this specific\n",
      "     |      scorer.\n",
      "     |  \n",
      "     |      See ``scoring`` parameter to know more about multiple metric\n",
      "     |      evaluation.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.20\n",
      "     |          Support for callable added.\n",
      "     |  \n",
      "     |  verbose : integer\n",
      "     |      Controls the verbosity: the higher, the more messages.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Pseudo random number generator state used for random uniform sampling\n",
      "     |      from lists of possible values instead of scipy.stats distributions.\n",
      "     |      Pass an int for reproducible output across multiple\n",
      "     |      function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  error_score : 'raise' or numeric, default=np.nan\n",
      "     |      Value to assign to the score if an error occurs in estimator fitting.\n",
      "     |      If set to 'raise', the error is raised. If a numeric value is given,\n",
      "     |      FitFailedWarning is raised. This parameter does not affect the refit\n",
      "     |      step, which will always raise the error.\n",
      "     |  \n",
      "     |  return_train_score : bool, default=False\n",
      "     |      If ``False``, the ``cv_results_`` attribute will not include training\n",
      "     |      scores.\n",
      "     |      Computing training scores is used to get insights on how different\n",
      "     |      parameter settings impact the overfitting/underfitting trade-off.\n",
      "     |      However computing the scores on the training set can be computationally\n",
      "     |      expensive and is not strictly required to select the parameters that\n",
      "     |      yield the best generalization performance.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.19\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.21\n",
      "     |          Default value was changed from ``True`` to ``False``\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  cv_results_ : dict of numpy (masked) ndarrays\n",
      "     |      A dict with keys as column headers and values as columns, that can be\n",
      "     |      imported into a pandas ``DataFrame``.\n",
      "     |  \n",
      "     |      For instance the below given table\n",
      "     |  \n",
      "     |      +--------------+-------------+-------------------+---+---------------+\n",
      "     |      | param_kernel | param_gamma | split0_test_score |...|rank_test_score|\n",
      "     |      +==============+=============+===================+===+===============+\n",
      "     |      |    'rbf'     |     0.1     |       0.80        |...|       2       |\n",
      "     |      +--------------+-------------+-------------------+---+---------------+\n",
      "     |      |    'rbf'     |     0.2     |       0.90        |...|       1       |\n",
      "     |      +--------------+-------------+-------------------+---+---------------+\n",
      "     |      |    'rbf'     |     0.3     |       0.70        |...|       1       |\n",
      "     |      +--------------+-------------+-------------------+---+---------------+\n",
      "     |  \n",
      "     |      will be represented by a ``cv_results_`` dict of::\n",
      "     |  \n",
      "     |          {\n",
      "     |          'param_kernel' : masked_array(data = ['rbf', 'rbf', 'rbf'],\n",
      "     |                                        mask = False),\n",
      "     |          'param_gamma'  : masked_array(data = [0.1 0.2 0.3], mask = False),\n",
      "     |          'split0_test_score'  : [0.80, 0.90, 0.70],\n",
      "     |          'split1_test_score'  : [0.82, 0.50, 0.70],\n",
      "     |          'mean_test_score'    : [0.81, 0.70, 0.70],\n",
      "     |          'std_test_score'     : [0.01, 0.20, 0.00],\n",
      "     |          'rank_test_score'    : [3, 1, 1],\n",
      "     |          'split0_train_score' : [0.80, 0.92, 0.70],\n",
      "     |          'split1_train_score' : [0.82, 0.55, 0.70],\n",
      "     |          'mean_train_score'   : [0.81, 0.74, 0.70],\n",
      "     |          'std_train_score'    : [0.01, 0.19, 0.00],\n",
      "     |          'mean_fit_time'      : [0.73, 0.63, 0.43],\n",
      "     |          'std_fit_time'       : [0.01, 0.02, 0.01],\n",
      "     |          'mean_score_time'    : [0.01, 0.06, 0.04],\n",
      "     |          'std_score_time'     : [0.00, 0.00, 0.00],\n",
      "     |          'params'             : [{'kernel' : 'rbf', 'gamma' : 0.1}, ...],\n",
      "     |          }\n",
      "     |  \n",
      "     |      NOTE\n",
      "     |  \n",
      "     |      The key ``'params'`` is used to store a list of parameter\n",
      "     |      settings dicts for all the parameter candidates.\n",
      "     |  \n",
      "     |      The ``mean_fit_time``, ``std_fit_time``, ``mean_score_time`` and\n",
      "     |      ``std_score_time`` are all in seconds.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, the scores for all the scorers are\n",
      "     |      available in the ``cv_results_`` dict at the keys ending with that\n",
      "     |      scorer's name (``'_<scorer_name>'``) instead of ``'_score'`` shown\n",
      "     |      above. ('split0_test_precision', 'mean_train_precision' etc.)\n",
      "     |  \n",
      "     |  best_estimator_ : estimator\n",
      "     |      Estimator that was chosen by the search, i.e. estimator\n",
      "     |      which gave highest score (or smallest loss if specified)\n",
      "     |      on the left out data. Not available if ``refit=False``.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this attribute is present only if\n",
      "     |      ``refit`` is specified.\n",
      "     |  \n",
      "     |      See ``refit`` parameter for more information on allowed values.\n",
      "     |  \n",
      "     |  best_score_ : float\n",
      "     |      Mean cross-validated score of the best_estimator.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      "     |      ``False``. See ``refit`` parameter for more information.\n",
      "     |  \n",
      "     |      This attribute is not available if ``refit`` is a function.\n",
      "     |  \n",
      "     |  best_params_ : dict\n",
      "     |      Parameter setting that gave the best results on the hold out data.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      "     |      ``False``. See ``refit`` parameter for more information.\n",
      "     |  \n",
      "     |  best_index_ : int\n",
      "     |      The index (of the ``cv_results_`` arrays) which corresponds to the best\n",
      "     |      candidate parameter setting.\n",
      "     |  \n",
      "     |      The dict at ``search.cv_results_['params'][search.best_index_]`` gives\n",
      "     |      the parameter setting for the best model, that gives the highest\n",
      "     |      mean score (``search.best_score_``).\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this is not available if ``refit`` is\n",
      "     |      ``False``. See ``refit`` parameter for more information.\n",
      "     |  \n",
      "     |  scorer_ : function or a dict\n",
      "     |      Scorer function used on the held out data to choose the best\n",
      "     |      parameters for the model.\n",
      "     |  \n",
      "     |      For multi-metric evaluation, this attribute holds the validated\n",
      "     |      ``scoring`` dict which maps the scorer key to the scorer callable.\n",
      "     |  \n",
      "     |  n_splits_ : int\n",
      "     |      The number of cross-validation splits (folds/iterations).\n",
      "     |  \n",
      "     |  refit_time_ : float\n",
      "     |      Seconds used for refitting the best model on the whole dataset.\n",
      "     |  \n",
      "     |      This is present only if ``refit`` is not False.\n",
      "     |  \n",
      "     |      .. versionadded:: 0.20\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The parameters selected are those that maximize the score of the held-out\n",
      "     |  data, according to the scoring parameter.\n",
      "     |  \n",
      "     |  If `n_jobs` was set to a value higher than one, the data is copied for each\n",
      "     |  parameter setting(and not `n_jobs` times). This is done for efficiency\n",
      "     |  reasons if individual jobs take very little time, but may raise errors if\n",
      "     |  the dataset is large and not enough memory is available.  A workaround in\n",
      "     |  this case is to set `pre_dispatch`. Then, the memory is copied only\n",
      "     |  `pre_dispatch` many times. A reasonable value for `pre_dispatch` is `2 *\n",
      "     |  n_jobs`.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  :class:`GridSearchCV`:\n",
      "     |      Does exhaustive search over a grid of parameters.\n",
      "     |  \n",
      "     |  :class:`ParameterSampler`:\n",
      "     |      A generator over parameter settings, constructed from\n",
      "     |      param_distributions.\n",
      "     |  \n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from sklearn.datasets import load_iris\n",
      "     |  >>> from sklearn.linear_model import LogisticRegression\n",
      "     |  >>> from sklearn.model_selection import RandomizedSearchCV\n",
      "     |  >>> from scipy.stats import uniform\n",
      "     |  >>> iris = load_iris()\n",
      "     |  >>> logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
      "     |  ...                               random_state=0)\n",
      "     |  >>> distributions = dict(C=uniform(loc=0, scale=4),\n",
      "     |  ...                      penalty=['l2', 'l1'])\n",
      "     |  >>> clf = RandomizedSearchCV(logistic, distributions, random_state=0)\n",
      "     |  >>> search = clf.fit(iris.data, iris.target)\n",
      "     |  >>> search.best_params_\n",
      "     |  {'C': 2..., 'penalty': 'l1'}\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RandomizedSearchCV\n",
      "     |      BaseSearchCV\n",
      "     |      sklearn.base.MetaEstimatorMixin\n",
      "     |      sklearn.base.BaseEstimator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, estimator, param_distributions, *, n_iter=10, scoring=None, n_jobs=None, iid='deprecated', refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', random_state=None, error_score=nan, return_train_score=False)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseSearchCV:\n",
      "     |  \n",
      "     |  decision_function(self, X)\n",
      "     |      Call decision_function on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``decision_function``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  fit(self, X, y=None, *, groups=None, **fit_params)\n",
      "     |      Run fit with all sets of parameters.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      \n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training vector, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "     |          instance (e.g., :class:`~sklearn.model_selection.GroupKFold`).\n",
      "     |      \n",
      "     |      **fit_params : dict of str -> object\n",
      "     |          Parameters passed to the ``fit`` method of the estimator\n",
      "     |  \n",
      "     |  inverse_transform(self, Xt)\n",
      "     |      Call inverse_transform on the estimator with the best found params.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator implements\n",
      "     |      ``inverse_transform`` and ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      Xt : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict(self, X)\n",
      "     |      Call predict on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_log_proba(self, X)\n",
      "     |      Call predict_log_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_log_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  predict_proba(self, X)\n",
      "     |      Call predict_proba on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if ``refit=True`` and the underlying estimator supports\n",
      "     |      ``predict_proba``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  score(self, X, y=None)\n",
      "     |      Returns the score on the given data, if the estimator has been refit.\n",
      "     |      \n",
      "     |      This uses the score defined by ``scoring`` where provided, and the\n",
      "     |      ``best_estimator_.score`` method otherwise.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Input data, where n_samples is the number of samples and\n",
      "     |          n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples, n_output)             or (n_samples,), default=None\n",
      "     |          Target relative to X for classification or regression;\n",
      "     |          None for unsupervised learning.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      score : float\n",
      "     |  \n",
      "     |  transform(self, X)\n",
      "     |      Call transform on the estimator with the best found parameters.\n",
      "     |      \n",
      "     |      Only available if the underlying estimator supports ``transform`` and\n",
      "     |      ``refit=True``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : indexable, length n_samples\n",
      "     |          Must fulfill the input assumptions of the\n",
      "     |          underlying estimator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Readonly properties inherited from BaseSearchCV:\n",
      "     |  \n",
      "     |  classes_\n",
      "     |  \n",
      "     |  n_features_in_\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from sklearn.base.MetaEstimatorMixin:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from sklearn.base.BaseEstimator:\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __repr__(self, N_CHAR_MAX=700)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  get_params(self, deep=True)\n",
      "     |      Get parameters for this estimator.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      deep : bool, default=True\n",
      "     |          If True, will return the parameters for this estimator and\n",
      "     |          contained subobjects that are estimators.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      params : mapping of string to any\n",
      "     |          Parameter names mapped to their values.\n",
      "     |  \n",
      "     |  set_params(self, **params)\n",
      "     |      Set the parameters of this estimator.\n",
      "     |      \n",
      "     |      The method works on simple estimators as well as on nested objects\n",
      "     |      (such as pipelines). The latter have parameters of the form\n",
      "     |      ``<component>__<parameter>`` so that it's possible to update each\n",
      "     |      component of a nested object.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      **params : dict\n",
      "     |          Estimator parameters.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : object\n",
      "     |          Estimator instance.\n",
      "    \n",
      "    class RepeatedKFold(_RepeatedSplits)\n",
      "     |  RepeatedKFold(*, n_splits=5, n_repeats=10, random_state=None)\n",
      "     |  \n",
      "     |  Repeated K-Fold cross validator.\n",
      "     |  \n",
      "     |  Repeats K-Fold n times with different randomization in each repetition.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |  n_repeats : int, default=10\n",
      "     |      Number of times cross-validator needs to be repeated.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the randomness of each repeated cross-validation instance.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import RepeatedKFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> rkf = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n",
      "     |  >>> for train_index, test_index in rkf.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...\n",
      "     |  TRAIN: [0 1] TEST: [2 3]\n",
      "     |  TRAIN: [2 3] TEST: [0 1]\n",
      "     |  TRAIN: [1 2] TEST: [0 3]\n",
      "     |  TRAIN: [0 3] TEST: [1 2]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Randomized CV splitters may return different results for each call of\n",
      "     |  split. You can make the results identical by setting `random_state`\n",
      "     |  to an integer.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RepeatedKFold\n",
      "     |      _RepeatedSplits\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, n_splits=5, n_repeats=10, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _RepeatedSplits:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |          ``np.zeros(n_samples)`` may be used as a placeholder.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |          ``np.zeros(n_samples)`` may be used as a placeholder.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generates indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of length n_samples\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _RepeatedSplits:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class RepeatedStratifiedKFold(_RepeatedSplits)\n",
      "     |  RepeatedStratifiedKFold(*, n_splits=5, n_repeats=10, random_state=None)\n",
      "     |  \n",
      "     |  Repeated Stratified K-Fold cross validator.\n",
      "     |  \n",
      "     |  Repeats Stratified K-Fold n times with different randomization in each\n",
      "     |  repetition.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |  n_repeats : int, default=10\n",
      "     |      Number of times cross-validator needs to be repeated.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the generation of the random states for each repetition.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import RepeatedStratifiedKFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> rskf = RepeatedStratifiedKFold(n_splits=2, n_repeats=2,\n",
      "     |  ...     random_state=36851234)\n",
      "     |  >>> for train_index, test_index in rskf.split(X, y):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  ...\n",
      "     |  TRAIN: [1 2] TEST: [0 3]\n",
      "     |  TRAIN: [0 3] TEST: [1 2]\n",
      "     |  TRAIN: [1 3] TEST: [0 2]\n",
      "     |  TRAIN: [0 2] TEST: [1 3]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Randomized CV splitters may return different results for each call of\n",
      "     |  split. You can make the results identical by setting `random_state`\n",
      "     |  to an integer.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  RepeatedKFold: Repeats K-Fold n times.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      RepeatedStratifiedKFold\n",
      "     |      _RepeatedSplits\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, *, n_splits=5, n_repeats=10, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _RepeatedSplits:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |          ``np.zeros(n_samples)`` may be used as a placeholder.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |          ``np.zeros(n_samples)`` may be used as a placeholder.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generates indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like, shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of length n_samples\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from _RepeatedSplits:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class ShuffleSplit(BaseShuffleSplit)\n",
      "     |  ShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      "     |  \n",
      "     |  Random permutation cross-validator\n",
      "     |  \n",
      "     |  Yields indices to split data into training and test sets.\n",
      "     |  \n",
      "     |  Note: contrary to other cross-validation strategies, random splits\n",
      "     |  do not guarantee that all folds will be different, although this is\n",
      "     |  still very likely for sizeable datasets.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=10\n",
      "     |      Number of re-shuffling & splitting iterations.\n",
      "     |  \n",
      "     |  test_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "     |      of the dataset to include in the test split. If int, represents the\n",
      "     |      absolute number of test samples. If None, the value is set to the\n",
      "     |      complement of the train size. If ``train_size`` is also None, it will\n",
      "     |      be set to 0.1.\n",
      "     |  \n",
      "     |  train_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the\n",
      "     |      proportion of the dataset to include in the train split. If\n",
      "     |      int, represents the absolute number of train samples. If None,\n",
      "     |      the value is automatically set to the complement of the test size.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the randomness of the training and testing indices produced.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import ShuffleSplit\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [3, 4], [5, 6]])\n",
      "     |  >>> y = np.array([1, 2, 1, 2, 1, 2])\n",
      "     |  >>> rs = ShuffleSplit(n_splits=5, test_size=.25, random_state=0)\n",
      "     |  >>> rs.get_n_splits(X)\n",
      "     |  5\n",
      "     |  >>> print(rs)\n",
      "     |  ShuffleSplit(n_splits=5, random_state=0, test_size=0.25, train_size=None)\n",
      "     |  >>> for train_index, test_index in rs.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  TRAIN: [1 3 0 4] TEST: [5 2]\n",
      "     |  TRAIN: [4 0 2 5] TEST: [1 3]\n",
      "     |  TRAIN: [1 2 4 0] TEST: [3 5]\n",
      "     |  TRAIN: [3 4 1 0] TEST: [5 2]\n",
      "     |  TRAIN: [3 5 1 0] TEST: [2 4]\n",
      "     |  >>> rs = ShuffleSplit(n_splits=5, train_size=0.5, test_size=.25,\n",
      "     |  ...                   random_state=0)\n",
      "     |  >>> for train_index, test_index in rs.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  TRAIN: [1 3 0] TEST: [5 2]\n",
      "     |  TRAIN: [4 0 2] TEST: [1 3]\n",
      "     |  TRAIN: [1 2 4] TEST: [3 5]\n",
      "     |  TRAIN: [3 4 1] TEST: [5 2]\n",
      "     |  TRAIN: [3 5 1] TEST: [2 4]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      ShuffleSplit\n",
      "     |      BaseShuffleSplit\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,), default=None\n",
      "     |          Group labels for the samples used while splitting the dataset into\n",
      "     |          train/test set.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Randomized CV splitters may return different results for each call of\n",
      "     |      split. You can make the results identical by setting `random_state`\n",
      "     |      to an integer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class StratifiedKFold(_BaseKFold)\n",
      "     |  StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)\n",
      "     |  \n",
      "     |  Stratified K-Folds cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets.\n",
      "     |  \n",
      "     |  This cross-validation object is a variation of KFold that returns\n",
      "     |  stratified folds. The folds are made by preserving the percentage of\n",
      "     |  samples for each class.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of folds. Must be at least 2.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``n_splits`` default value changed from 3 to 5.\n",
      "     |  \n",
      "     |  shuffle : bool, default=False\n",
      "     |      Whether to shuffle each class's samples before splitting into batches.\n",
      "     |      Note that the samples within each split will not be shuffled.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      When `shuffle` is True, `random_state` affects the ordering of the\n",
      "     |      indices, which controls the randomness of each fold for each class.\n",
      "     |      Otherwise, leave `random_state` as `None`.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import StratifiedKFold\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 1, 1])\n",
      "     |  >>> skf = StratifiedKFold(n_splits=2)\n",
      "     |  >>> skf.get_n_splits(X, y)\n",
      "     |  2\n",
      "     |  >>> print(skf)\n",
      "     |  StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
      "     |  >>> for train_index, test_index in skf.split(X, y):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [1 3] TEST: [0 2]\n",
      "     |  TRAIN: [0 2] TEST: [1 3]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The implementation is designed to:\n",
      "     |  \n",
      "     |  * Generate test sets such that all contain the same distribution of\n",
      "     |    classes, or as close as possible.\n",
      "     |  * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n",
      "     |    ``y = [1, 0]`` should not change the indices generated.\n",
      "     |  * Preserve order dependencies in the dataset ordering, when\n",
      "     |    ``shuffle=False``: all samples from class k in some test set were\n",
      "     |    contiguous in y, or separated in y by samples from classes other than k.\n",
      "     |  * Generate test sets where the smallest and largest differ by at most one\n",
      "     |    sample.\n",
      "     |  \n",
      "     |  .. versionchanged:: 0.22\n",
      "     |      The previous implementation did not follow the last constraint.\n",
      "     |  \n",
      "     |  See also\n",
      "     |  --------\n",
      "     |  RepeatedStratifiedKFold: Repeats Stratified K-Fold n times.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StratifiedKFold\n",
      "     |      _BaseKFold\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5, *, shuffle=False, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |          Note that providing ``y`` is sufficient to generate the splits and\n",
      "     |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      "     |          ``X`` instead of actual training data.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |          Stratification is done based on the y labels.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Randomized CV splitters may return different results for each call of\n",
      "     |      split. You can make the results identical by setting `random_state`\n",
      "     |      to an integer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseKFold:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class StratifiedShuffleSplit(BaseShuffleSplit)\n",
      "     |  StratifiedShuffleSplit(n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      "     |  \n",
      "     |  Stratified ShuffleSplit cross-validator\n",
      "     |  \n",
      "     |  Provides train/test indices to split data in train/test sets.\n",
      "     |  \n",
      "     |  This cross-validation object is a merge of StratifiedKFold and\n",
      "     |  ShuffleSplit, which returns stratified randomized folds. The folds\n",
      "     |  are made by preserving the percentage of samples for each class.\n",
      "     |  \n",
      "     |  Note: like the ShuffleSplit strategy, stratified random splits\n",
      "     |  do not guarantee that all folds will be different, although this is\n",
      "     |  still very likely for sizeable datasets.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=10\n",
      "     |      Number of re-shuffling & splitting iterations.\n",
      "     |  \n",
      "     |  test_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "     |      of the dataset to include in the test split. If int, represents the\n",
      "     |      absolute number of test samples. If None, the value is set to the\n",
      "     |      complement of the train size. If ``train_size`` is also None, it will\n",
      "     |      be set to 0.1.\n",
      "     |  \n",
      "     |  train_size : float or int, default=None\n",
      "     |      If float, should be between 0.0 and 1.0 and represent the\n",
      "     |      proportion of the dataset to include in the train split. If\n",
      "     |      int, represents the absolute number of train samples. If None,\n",
      "     |      the value is automatically set to the complement of the test size.\n",
      "     |  \n",
      "     |  random_state : int or RandomState instance, default=None\n",
      "     |      Controls the randomness of the training and testing indices produced.\n",
      "     |      Pass an int for reproducible output across multiple function calls.\n",
      "     |      See :term:`Glossary <random_state>`.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import StratifiedShuffleSplit\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([0, 0, 0, 1, 1, 1])\n",
      "     |  >>> sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)\n",
      "     |  >>> sss.get_n_splits(X, y)\n",
      "     |  5\n",
      "     |  >>> print(sss)\n",
      "     |  StratifiedShuffleSplit(n_splits=5, random_state=0, ...)\n",
      "     |  >>> for train_index, test_index in sss.split(X, y):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [5 2 3] TEST: [4 1 0]\n",
      "     |  TRAIN: [5 1 4] TEST: [0 2 3]\n",
      "     |  TRAIN: [5 0 2] TEST: [4 3 1]\n",
      "     |  TRAIN: [4 1 0] TEST: [2 3 5]\n",
      "     |  TRAIN: [0 5 1] TEST: [3 4 2]\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      StratifiedShuffleSplit\n",
      "     |      BaseShuffleSplit\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=10, *, test_size=None, train_size=None, random_state=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |          Note that providing ``y`` is sufficient to generate the splits and\n",
      "     |          hence ``np.zeros(n_samples)`` may be used as a placeholder for\n",
      "     |          ``X`` instead of actual training data.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,) or (n_samples, n_labels)\n",
      "     |          The target variable for supervised learning problems.\n",
      "     |          Stratification is done based on the y labels.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Randomized CV splitters may return different results for each call of\n",
      "     |      split. You can make the results identical by setting `random_state`\n",
      "     |      to an integer.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseShuffleSplit:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "    \n",
      "    class TimeSeriesSplit(_BaseKFold)\n",
      "     |  TimeSeriesSplit(n_splits=5, *, max_train_size=None)\n",
      "     |  \n",
      "     |  Time Series cross-validator\n",
      "     |  \n",
      "     |  .. versionadded:: 0.18\n",
      "     |  \n",
      "     |  Provides train/test indices to split time series data samples\n",
      "     |  that are observed at fixed time intervals, in train/test sets.\n",
      "     |  In each split, test indices must be higher than before, and thus shuffling\n",
      "     |  in cross validator is inappropriate.\n",
      "     |  \n",
      "     |  This cross-validation object is a variation of :class:`KFold`.\n",
      "     |  In the kth split, it returns first k folds as train set and the\n",
      "     |  (k+1)th fold as test set.\n",
      "     |  \n",
      "     |  Note that unlike standard cross-validation methods, successive\n",
      "     |  training sets are supersets of those that come before them.\n",
      "     |  \n",
      "     |  Read more in the :ref:`User Guide <cross_validation>`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  n_splits : int, default=5\n",
      "     |      Number of splits. Must be at least 2.\n",
      "     |  \n",
      "     |      .. versionchanged:: 0.22\n",
      "     |          ``n_splits`` default value changed from 3 to 5.\n",
      "     |  \n",
      "     |  max_train_size : int, default=None\n",
      "     |      Maximum size for a single training set.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> from sklearn.model_selection import TimeSeriesSplit\n",
      "     |  >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
      "     |  >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
      "     |  >>> tscv = TimeSeriesSplit()\n",
      "     |  >>> print(tscv)\n",
      "     |  TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
      "     |  >>> for train_index, test_index in tscv.split(X):\n",
      "     |  ...     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "     |  ...     X_train, X_test = X[train_index], X[test_index]\n",
      "     |  ...     y_train, y_test = y[train_index], y[test_index]\n",
      "     |  TRAIN: [0] TEST: [1]\n",
      "     |  TRAIN: [0 1] TEST: [2]\n",
      "     |  TRAIN: [0 1 2] TEST: [3]\n",
      "     |  TRAIN: [0 1 2 3] TEST: [4]\n",
      "     |  TRAIN: [0 1 2 3 4] TEST: [5]\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The training set has size ``i * n_samples // (n_splits + 1)\n",
      "     |  + n_samples % (n_splits + 1)`` in the ``i``th split,\n",
      "     |  with a test set of size ``n_samples//(n_splits + 1)``,\n",
      "     |  where ``n_samples`` is the number of samples.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      TimeSeriesSplit\n",
      "     |      _BaseKFold\n",
      "     |      BaseCrossValidator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, n_splits=5, *, max_train_size=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  split(self, X, y=None, groups=None)\n",
      "     |      Generate indices to split data into training and test set.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : array-like of shape (n_samples, n_features)\n",
      "     |          Training data, where n_samples is the number of samples\n",
      "     |          and n_features is the number of features.\n",
      "     |      \n",
      "     |      y : array-like of shape (n_samples,)\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : array-like of shape (n_samples,)\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Yields\n",
      "     |      ------\n",
      "     |      train : ndarray\n",
      "     |          The training set indices for that split.\n",
      "     |      \n",
      "     |      test : ndarray\n",
      "     |          The testing set indices for that split.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __abstractmethods__ = frozenset()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from _BaseKFold:\n",
      "     |  \n",
      "     |  get_n_splits(self, X=None, y=None, groups=None)\n",
      "     |      Returns the number of splitting iterations in the cross-validator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      X : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      y : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      groups : object\n",
      "     |          Always ignored, exists for compatibility.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      n_splits : int\n",
      "     |          Returns the number of splitting iterations in the cross-validator.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __repr__(self)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from BaseCrossValidator:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "\n",
      "FUNCTIONS\n",
      "    check_cv(cv=5, y=None, *, classifier=False)\n",
      "        Input checker utility for building a cross-validator\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - integer, to specify the number of folds.\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For integer/None inputs, if classifier is True and ``y`` is either\n",
      "            binary or multiclass, :class:`StratifiedKFold` is used. In all other\n",
      "            cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value changed from 3-fold to 5-fold.\n",
      "        \n",
      "        y : array-like, default=None\n",
      "            The target variable for supervised learning problems.\n",
      "        \n",
      "        classifier : bool, default=False\n",
      "            Whether the task is a classification task, in which case\n",
      "            stratified KFold will be used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        checked_cv : a cross-validator instance.\n",
      "            The return value is a cross-validator which generates the train/test\n",
      "            splits via the ``split`` method.\n",
      "    \n",
      "    cross_val_predict(estimator, X, y=None, *, groups=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', method='predict')\n",
      "        Generate cross-validated estimates for each input data point\n",
      "        \n",
      "        The data is split according to the cv parameter. Each sample belongs\n",
      "        to exactly one test set, and its prediction is computed with an\n",
      "        estimator fitted on the corresponding training set.\n",
      "        \n",
      "        Passing these predictions into an evaluation metric may not be a valid\n",
      "        way to measure generalization performance. Results can differ from\n",
      "        :func:`cross_validate` and :func:`cross_val_score` unless all tests sets\n",
      "        have equal size and the metric decomposes over samples.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit' and 'predict'\n",
      "            The object to use to fit the data.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The data to fit. Can be, for example a list, or an array at least 2d.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "            The target variable to try to predict in the case of\n",
      "            supervised learning.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of CPUs to use to do the computation.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            The verbosity level.\n",
      "        \n",
      "        fit_params : dict, defualt=None\n",
      "            Parameters to pass to the fit method of the estimator.\n",
      "        \n",
      "        pre_dispatch : int or str, default='2*n_jobs'\n",
      "            Controls the number of jobs that get dispatched during parallel\n",
      "            execution. Reducing this number can be useful to avoid an\n",
      "            explosion of memory consumption when more jobs get dispatched\n",
      "            than CPUs can process. This parameter can be:\n",
      "        \n",
      "                - None, in which case all the jobs are immediately\n",
      "                  created and spawned. Use this for lightweight and\n",
      "                  fast-running jobs, to avoid delays due to on-demand\n",
      "                  spawning of the jobs\n",
      "        \n",
      "                - An int, giving the exact number of total jobs that are\n",
      "                  spawned\n",
      "        \n",
      "                - A str, giving an expression as a function of n_jobs,\n",
      "                  as in '2*n_jobs'\n",
      "        \n",
      "        method : str, default='predict'\n",
      "            Invokes the passed method name of the passed estimator. For\n",
      "            method='predict_proba', the columns correspond to the classes\n",
      "            in sorted order.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        predictions : ndarray\n",
      "            This is the result of calling ``method``\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        cross_val_score : calculate score for each CV split\n",
      "        \n",
      "        cross_validate : calculate one or more scores and timings for each CV split\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In the case that one or more classes are absent in a training portion, a\n",
      "        default score needs to be assigned to all instances for that class if\n",
      "        ``method`` produces columns per class, as in {'decision_function',\n",
      "        'predict_proba', 'predict_log_proba'}.  For ``predict_proba`` this value is\n",
      "        0.  In order to ensure finite output, we approximate negative infinity by\n",
      "        the minimum finite float value for the dtype in other cases.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn import datasets, linear_model\n",
      "        >>> from sklearn.model_selection import cross_val_predict\n",
      "        >>> diabetes = datasets.load_diabetes()\n",
      "        >>> X = diabetes.data[:150]\n",
      "        >>> y = diabetes.target[:150]\n",
      "        >>> lasso = linear_model.Lasso()\n",
      "        >>> y_pred = cross_val_predict(lasso, X, y, cv=3)\n",
      "    \n",
      "    cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', error_score=nan)\n",
      "        Evaluate a score by cross-validation\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit'\n",
      "            The object to use to fit the data.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The data to fit. Can be for example a list, or an array.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "            The target variable to try to predict in the case of\n",
      "            supervised learning.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        scoring : str or callable, default=None\n",
      "            A str (see model evaluation documentation) or\n",
      "            a scorer callable object / function with signature\n",
      "            ``scorer(estimator, X, y)`` which should return only\n",
      "            a single value.\n",
      "        \n",
      "            Similar to :func:`cross_validate`\n",
      "            but only a single metric is permitted.\n",
      "        \n",
      "            If None, the estimator's default scorer (if available) is used.\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of CPUs to use to do the computation.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            The verbosity level.\n",
      "        \n",
      "        fit_params : dict, default=None\n",
      "            Parameters to pass to the fit method of the estimator.\n",
      "        \n",
      "        pre_dispatch : int or str, default='2*n_jobs'\n",
      "            Controls the number of jobs that get dispatched during parallel\n",
      "            execution. Reducing this number can be useful to avoid an\n",
      "            explosion of memory consumption when more jobs get dispatched\n",
      "            than CPUs can process. This parameter can be:\n",
      "        \n",
      "                - None, in which case all the jobs are immediately\n",
      "                  created and spawned. Use this for lightweight and\n",
      "                  fast-running jobs, to avoid delays due to on-demand\n",
      "                  spawning of the jobs\n",
      "        \n",
      "                - An int, giving the exact number of total jobs that are\n",
      "                  spawned\n",
      "        \n",
      "                - A str, giving an expression as a function of n_jobs,\n",
      "                  as in '2*n_jobs'\n",
      "        \n",
      "        error_score : 'raise' or numeric, default=np.nan\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised.\n",
      "            If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "            does not affect the refit step, which will always raise the error.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        scores : array of float, shape=(len(list(cv)),)\n",
      "            Array of scores of the estimator for each run of the cross validation.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn import datasets, linear_model\n",
      "        >>> from sklearn.model_selection import cross_val_score\n",
      "        >>> diabetes = datasets.load_diabetes()\n",
      "        >>> X = diabetes.data[:150]\n",
      "        >>> y = diabetes.target[:150]\n",
      "        >>> lasso = linear_model.Lasso()\n",
      "        >>> print(cross_val_score(lasso, X, y, cv=3))\n",
      "        [0.33150734 0.08022311 0.03531764]\n",
      "        \n",
      "        See Also\n",
      "        ---------\n",
      "        :func:`sklearn.model_selection.cross_validate`:\n",
      "            To run cross-validation on multiple metrics and also to return\n",
      "            train scores, fit times and score times.\n",
      "        \n",
      "        :func:`sklearn.model_selection.cross_val_predict`:\n",
      "            Get predictions from each split of cross-validation for diagnostic\n",
      "            purposes.\n",
      "        \n",
      "        :func:`sklearn.metrics.make_scorer`:\n",
      "            Make a scorer from a performance metric or loss function.\n",
      "    \n",
      "    cross_validate(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, verbose=0, fit_params=None, pre_dispatch='2*n_jobs', return_train_score=False, return_estimator=False, error_score=nan)\n",
      "        Evaluate metric(s) by cross-validation and also record fit/score times.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <multimetric_cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit'\n",
      "            The object to use to fit the data.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            The data to fit. Can be for example a list, or an array.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs),             default=None\n",
      "            The target variable to try to predict in the case of\n",
      "            supervised learning.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        scoring : str, callable, list/tuple, or dict, default=None\n",
      "            A single str (see :ref:`scoring_parameter`) or a callable\n",
      "            (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "        \n",
      "            For evaluating multiple metrics, either give a list of (unique) strings\n",
      "            or a dict with names as keys and callables as values.\n",
      "        \n",
      "            NOTE that when using custom scorers, each scorer should return a single\n",
      "            value. Metric functions returning a list/array of values can be wrapped\n",
      "            into multiple scorers that return one value each.\n",
      "        \n",
      "            See :ref:`multimetric_grid_search` for an example.\n",
      "        \n",
      "            If None, the estimator's score method is used.\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of CPUs to use to do the computation.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            The verbosity level.\n",
      "        \n",
      "        fit_params : dict, default=None\n",
      "            Parameters to pass to the fit method of the estimator.\n",
      "        \n",
      "        pre_dispatch : int or str, default='2*n_jobs'\n",
      "            Controls the number of jobs that get dispatched during parallel\n",
      "            execution. Reducing this number can be useful to avoid an\n",
      "            explosion of memory consumption when more jobs get dispatched\n",
      "            than CPUs can process. This parameter can be:\n",
      "        \n",
      "                - None, in which case all the jobs are immediately\n",
      "                  created and spawned. Use this for lightweight and\n",
      "                  fast-running jobs, to avoid delays due to on-demand\n",
      "                  spawning of the jobs\n",
      "        \n",
      "                - An int, giving the exact number of total jobs that are\n",
      "                  spawned\n",
      "        \n",
      "                - A str, giving an expression as a function of n_jobs,\n",
      "                  as in '2*n_jobs'\n",
      "        \n",
      "        return_train_score : bool, default=False\n",
      "            Whether to include train scores.\n",
      "            Computing training scores is used to get insights on how different\n",
      "            parameter settings impact the overfitting/underfitting trade-off.\n",
      "            However computing the scores on the training set can be computationally\n",
      "            expensive and is not strictly required to select the parameters that\n",
      "            yield the best generalization performance.\n",
      "        \n",
      "            .. versionadded:: 0.19\n",
      "        \n",
      "            .. versionchanged:: 0.21\n",
      "                Default value was changed from ``True`` to ``False``\n",
      "        \n",
      "        return_estimator : bool, default=False\n",
      "            Whether to return the estimators fitted on each split.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        error_score : 'raise' or numeric\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised.\n",
      "            If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "            does not affect the refit step, which will always raise the error.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        scores : dict of float arrays of shape (n_splits,)\n",
      "            Array of scores of the estimator for each run of the cross validation.\n",
      "        \n",
      "            A dict of arrays containing the score/time arrays for each scorer is\n",
      "            returned. The possible keys for this ``dict`` are:\n",
      "        \n",
      "                ``test_score``\n",
      "                    The score array for test scores on each cv split.\n",
      "                    Suffix ``_score`` in ``test_score`` changes to a specific\n",
      "                    metric like ``test_r2`` or ``test_auc`` if there are\n",
      "                    multiple scoring metrics in the scoring parameter.\n",
      "                ``train_score``\n",
      "                    The score array for train scores on each cv split.\n",
      "                    Suffix ``_score`` in ``train_score`` changes to a specific\n",
      "                    metric like ``train_r2`` or ``train_auc`` if there are\n",
      "                    multiple scoring metrics in the scoring parameter.\n",
      "                    This is available only if ``return_train_score`` parameter\n",
      "                    is ``True``.\n",
      "                ``fit_time``\n",
      "                    The time for fitting the estimator on the train\n",
      "                    set for each cv split.\n",
      "                ``score_time``\n",
      "                    The time for scoring the estimator on the test set for each\n",
      "                    cv split. (Note time for scoring on the train set is not\n",
      "                    included even if ``return_train_score`` is set to ``True``\n",
      "                ``estimator``\n",
      "                    The estimator objects for each cv split.\n",
      "                    This is available only if ``return_estimator`` parameter\n",
      "                    is set to ``True``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from sklearn import datasets, linear_model\n",
      "        >>> from sklearn.model_selection import cross_validate\n",
      "        >>> from sklearn.metrics import make_scorer\n",
      "        >>> from sklearn.metrics import confusion_matrix\n",
      "        >>> from sklearn.svm import LinearSVC\n",
      "        >>> diabetes = datasets.load_diabetes()\n",
      "        >>> X = diabetes.data[:150]\n",
      "        >>> y = diabetes.target[:150]\n",
      "        >>> lasso = linear_model.Lasso()\n",
      "        \n",
      "        Single metric evaluation using ``cross_validate``\n",
      "        \n",
      "        >>> cv_results = cross_validate(lasso, X, y, cv=3)\n",
      "        >>> sorted(cv_results.keys())\n",
      "        ['fit_time', 'score_time', 'test_score']\n",
      "        >>> cv_results['test_score']\n",
      "        array([0.33150734, 0.08022311, 0.03531764])\n",
      "        \n",
      "        Multiple metric evaluation using ``cross_validate``\n",
      "        (please refer the ``scoring`` parameter doc for more information)\n",
      "        \n",
      "        >>> scores = cross_validate(lasso, X, y, cv=3,\n",
      "        ...                         scoring=('r2', 'neg_mean_squared_error'),\n",
      "        ...                         return_train_score=True)\n",
      "        >>> print(scores['test_neg_mean_squared_error'])\n",
      "        [-3635.5... -3573.3... -6114.7...]\n",
      "        >>> print(scores['train_r2'])\n",
      "        [0.28010158 0.39088426 0.22784852]\n",
      "        \n",
      "        See Also\n",
      "        ---------\n",
      "        :func:`sklearn.model_selection.cross_val_score`:\n",
      "            Run cross-validation for single metric evaluation.\n",
      "        \n",
      "        :func:`sklearn.model_selection.cross_val_predict`:\n",
      "            Get predictions from each split of cross-validation for diagnostic\n",
      "            purposes.\n",
      "        \n",
      "        :func:`sklearn.metrics.make_scorer`:\n",
      "            Make a scorer from a performance metric or loss function.\n",
      "    \n",
      "    fit_grid_point(X, y, estimator, parameters, train, test, scorer, verbose, error_score=nan, **fit_params)\n",
      "        DEPRECATED: fit_grid_point is deprecated in version 0.23 and will be removed in version 0.25\n",
      "        \n",
      "        Run fit on one set of parameters.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        X : array-like, sparse matrix or list\n",
      "            Input data.\n",
      "        \n",
      "        y : array-like or None\n",
      "            Targets for input data.\n",
      "        \n",
      "        estimator : estimator object\n",
      "            A object of that type is instantiated for each grid point.\n",
      "            This is assumed to implement the scikit-learn estimator interface.\n",
      "            Either estimator needs to provide a ``score`` function,\n",
      "            or ``scoring`` must be passed.\n",
      "        \n",
      "        parameters : dict\n",
      "            Parameters to be set on estimator for this grid point.\n",
      "        \n",
      "        train : ndarray, dtype int or bool\n",
      "            Boolean mask or indices for training set.\n",
      "        \n",
      "        test : ndarray, dtype int or bool\n",
      "            Boolean mask or indices for test set.\n",
      "        \n",
      "        scorer : callable or None\n",
      "            The scorer callable object / function must have its signature as\n",
      "            ``scorer(estimator, X, y)``.\n",
      "        \n",
      "            If ``None`` the estimator's score method is used.\n",
      "        \n",
      "        verbose : int\n",
      "            Verbosity level.\n",
      "        \n",
      "        **fit_params : kwargs\n",
      "            Additional parameter passed to the fit function of the estimator.\n",
      "        \n",
      "        error_score : 'raise' or numeric, default=np.nan\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised. If a numeric value is given,\n",
      "            FitFailedWarning is raised. This parameter does not affect the refit\n",
      "            step, which will always raise the error.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "             Score of this parameter setting on given test split.\n",
      "        \n",
      "        parameters : dict\n",
      "            The parameters that have been evaluated.\n",
      "        \n",
      "        n_samples_test : int\n",
      "            Number of test samples in this split.\n",
      "    \n",
      "    learning_curve(estimator, X, y, *, groups=None, train_sizes=array([0.1  , 0.325, 0.55 , 0.775, 1.   ]), cv=None, scoring=None, exploit_incremental_learning=False, n_jobs=None, pre_dispatch='all', verbose=0, shuffle=False, random_state=None, error_score=nan, return_times=False)\n",
      "        Learning curve.\n",
      "        \n",
      "        Determines cross-validated training and test scores for different training\n",
      "        set sizes.\n",
      "        \n",
      "        A cross-validation generator splits the whole dataset k times in training\n",
      "        and test data. Subsets of the training set with varying sizes will be used\n",
      "        to train the estimator and a score for each training subset size and the\n",
      "        test set will be computed. Afterwards, the scores will be averaged over\n",
      "        all k runs for each training subset size.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <learning_curve>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : object type that implements the \"fit\" and \"predict\" methods\n",
      "            An object of that type which is cloned for each validation.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Training vector, where n_samples is the number of samples and\n",
      "            n_features is the number of features.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            Target relative to X for classification or regression;\n",
      "            None for unsupervised learning.\n",
      "        \n",
      "        groups : array-like of  shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        train_sizes : array-like of shape (n_ticks,),             default=np.linspace(0.1, 1.0, 5)\n",
      "            Relative or absolute numbers of training examples that will be used to\n",
      "            generate the learning curve. If the dtype is float, it is regarded as a\n",
      "            fraction of the maximum size of the training set (that is determined\n",
      "            by the selected validation method), i.e. it has to be within (0, 1].\n",
      "            Otherwise it is interpreted as absolute sizes of the training sets.\n",
      "            Note that for classification the number of samples usually have to\n",
      "            be big enough to contain at least one sample from each class.\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        scoring : str or callable, default=None\n",
      "            A str (see model evaluation documentation) or\n",
      "            a scorer callable object / function with signature\n",
      "            ``scorer(estimator, X, y)``.\n",
      "        \n",
      "        exploit_incremental_learning : bool, default=False\n",
      "            If the estimator supports incremental learning, this will be\n",
      "            used to speed up fitting for different training set sizes.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            Number of jobs to run in parallel.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        pre_dispatch : int or str, default='all'\n",
      "            Number of predispatched jobs for parallel execution (default is\n",
      "            all). The option can reduce the allocated memory. The str can\n",
      "            be an expression like '2*n_jobs'.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            Controls the verbosity: the higher, the more messages.\n",
      "        \n",
      "        shuffle : bool, default=False\n",
      "            Whether to shuffle training data before taking prefixes of it\n",
      "            based on``train_sizes``.\n",
      "        \n",
      "        random_state : int or RandomState instance, default=None\n",
      "            Used when ``shuffle`` is True. Pass an int for reproducible\n",
      "            output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        error_score : 'raise' or numeric, default=np.nan\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised.\n",
      "            If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "            does not affect the refit step, which will always raise the error.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        return_times : bool, default=False\n",
      "            Whether to return the fit and score times.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        train_sizes_abs : array of shape (n_unique_ticks,)\n",
      "            Numbers of training examples that has been used to generate the\n",
      "            learning curve. Note that the number of ticks might be less\n",
      "            than n_ticks because duplicate entries will be removed.\n",
      "        \n",
      "        train_scores : array of shape (n_ticks, n_cv_folds)\n",
      "            Scores on training sets.\n",
      "        \n",
      "        test_scores : array of shape (n_ticks, n_cv_folds)\n",
      "            Scores on test set.\n",
      "        \n",
      "        fit_times : array of shape (n_ticks, n_cv_folds)\n",
      "            Times spent for fitting in seconds. Only present if ``return_times``\n",
      "            is True.\n",
      "        \n",
      "        score_times : array of shape (n_ticks, n_cv_folds)\n",
      "            Times spent for scoring in seconds. Only present if ``return_times``\n",
      "            is True.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See :ref:`examples/model_selection/plot_learning_curve.py\n",
      "        <sphx_glr_auto_examples_model_selection_plot_learning_curve.py>`\n",
      "    \n",
      "    permutation_test_score(estimator, X, y, *, groups=None, cv=None, n_permutations=100, n_jobs=None, random_state=0, verbose=0, scoring=None)\n",
      "        Evaluate the significance of a cross-validated score with permutations\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : estimator object implementing 'fit'\n",
      "            The object to use to fit the data.\n",
      "        \n",
      "        X : array-like of shape at least 2D\n",
      "            The data to fit.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None\n",
      "            The target variable to try to predict in the case of\n",
      "            supervised learning.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Labels to constrain permutation within groups, i.e. ``y`` values\n",
      "            are permuted among samples with the same group identifier.\n",
      "            When not specified, ``y`` values are permuted among all samples.\n",
      "        \n",
      "            When a grouped cross-validator is used, the group labels are\n",
      "            also passed on to the ``split`` method of the cross-validator. The\n",
      "            cross-validator uses them for grouping the samples  while splitting\n",
      "            the dataset into train/test set.\n",
      "        \n",
      "        scoring : str or callable, default=None\n",
      "            A single str (see :ref:`scoring_parameter`) or a callable\n",
      "            (see :ref:`scoring`) to evaluate the predictions on the test set.\n",
      "        \n",
      "            If None the estimator's score method is used.\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        n_permutations : int, default=100\n",
      "            Number of times to permute ``y``.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            The number of CPUs to use to do the computation.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        random_state : int, RandomState instance or None, default=0\n",
      "            Pass an int for reproducible output for permutation of\n",
      "            ``y`` values among samples. See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            The verbosity level.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float\n",
      "            The true score without permuting targets.\n",
      "        \n",
      "        permutation_scores : array of shape (n_permutations,)\n",
      "            The scores obtained for each permutations.\n",
      "        \n",
      "        pvalue : float\n",
      "            The p-value, which approximates the probability that the score would\n",
      "            be obtained by chance. This is calculated as:\n",
      "        \n",
      "            `(C + 1) / (n_permutations + 1)`\n",
      "        \n",
      "            Where C is the number of permutations whose score >= the true score.\n",
      "        \n",
      "            The best possible p-value is 1/(n_permutations + 1), the worst is 1.0.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function implements Test 1 in:\n",
      "        \n",
      "            Ojala and Garriga. Permutation Tests for Studying Classifier\n",
      "            Performance.  The Journal of Machine Learning Research (2010)\n",
      "            vol. 11\n",
      "            `[pdf] <http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf>`_.\n",
      "    \n",
      "    train_test_split(*arrays, **options)\n",
      "        Split arrays or matrices into random train and test subsets\n",
      "        \n",
      "        Quick utility that wraps input validation and\n",
      "        ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "        into a single call for splitting (and optionally subsampling) data in a\n",
      "        oneliner.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <cross_validation>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        *arrays : sequence of indexables with same length / shape[0]\n",
      "            Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "            matrices or pandas dataframes.\n",
      "        \n",
      "        test_size : float or int, default=None\n",
      "            If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "            of the dataset to include in the test split. If int, represents the\n",
      "            absolute number of test samples. If None, the value is set to the\n",
      "            complement of the train size. If ``train_size`` is also None, it will\n",
      "            be set to 0.25.\n",
      "        \n",
      "        train_size : float or int, default=None\n",
      "            If float, should be between 0.0 and 1.0 and represent the\n",
      "            proportion of the dataset to include in the train split. If\n",
      "            int, represents the absolute number of train samples. If None,\n",
      "            the value is automatically set to the complement of the test size.\n",
      "        \n",
      "        random_state : int or RandomState instance, default=None\n",
      "            Controls the shuffling applied to the data before applying the split.\n",
      "            Pass an int for reproducible output across multiple function calls.\n",
      "            See :term:`Glossary <random_state>`.\n",
      "        \n",
      "        \n",
      "        shuffle : bool, default=True\n",
      "            Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "            then stratify must be None.\n",
      "        \n",
      "        stratify : array-like, default=None\n",
      "            If not None, data is split in a stratified fashion, using this as\n",
      "            the class labels.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        splitting : list, length=2 * len(arrays)\n",
      "            List containing train-test split of inputs.\n",
      "        \n",
      "            .. versionadded:: 0.16\n",
      "                If the input is sparse, the output will be a\n",
      "                ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "                input type.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import numpy as np\n",
      "        >>> from sklearn.model_selection import train_test_split\n",
      "        >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "        >>> X\n",
      "        array([[0, 1],\n",
      "               [2, 3],\n",
      "               [4, 5],\n",
      "               [6, 7],\n",
      "               [8, 9]])\n",
      "        >>> list(y)\n",
      "        [0, 1, 2, 3, 4]\n",
      "        \n",
      "        >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "        ...     X, y, test_size=0.33, random_state=42)\n",
      "        ...\n",
      "        >>> X_train\n",
      "        array([[4, 5],\n",
      "               [0, 1],\n",
      "               [6, 7]])\n",
      "        >>> y_train\n",
      "        [2, 0, 3]\n",
      "        >>> X_test\n",
      "        array([[2, 3],\n",
      "               [8, 9]])\n",
      "        >>> y_test\n",
      "        [1, 4]\n",
      "        \n",
      "        >>> train_test_split(y, shuffle=False)\n",
      "        [[0, 1, 2], [3, 4]]\n",
      "    \n",
      "    validation_curve(estimator, X, y, *, param_name, param_range, groups=None, cv=None, scoring=None, n_jobs=None, pre_dispatch='all', verbose=0, error_score=nan)\n",
      "        Validation curve.\n",
      "        \n",
      "        Determine training and test scores for varying parameter values.\n",
      "        \n",
      "        Compute scores for an estimator with different values of a specified\n",
      "        parameter. This is similar to grid search with one parameter. However, this\n",
      "        will also compute training scores and is merely a utility for plotting the\n",
      "        results.\n",
      "        \n",
      "        Read more in the :ref:`User Guide <validation_curve>`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        estimator : object type that implements the \"fit\" and \"predict\" methods\n",
      "            An object of that type which is cloned for each validation.\n",
      "        \n",
      "        X : array-like of shape (n_samples, n_features)\n",
      "            Training vector, where n_samples is the number of samples and\n",
      "            n_features is the number of features.\n",
      "        \n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs) or None\n",
      "            Target relative to X for classification or regression;\n",
      "            None for unsupervised learning.\n",
      "        \n",
      "        param_name : str\n",
      "            Name of the parameter that will be varied.\n",
      "        \n",
      "        param_range : array-like of shape (n_values,)\n",
      "            The values of the parameter that will be evaluated.\n",
      "        \n",
      "        groups : array-like of shape (n_samples,), default=None\n",
      "            Group labels for the samples used while splitting the dataset into\n",
      "            train/test set. Only used in conjunction with a \"Group\" :term:`cv`\n",
      "            instance (e.g., :class:`GroupKFold`).\n",
      "        \n",
      "        cv : int, cross-validation generator or an iterable, default=None\n",
      "            Determines the cross-validation splitting strategy.\n",
      "            Possible inputs for cv are:\n",
      "        \n",
      "            - None, to use the default 5-fold cross validation,\n",
      "            - int, to specify the number of folds in a `(Stratified)KFold`,\n",
      "            - :term:`CV splitter`,\n",
      "            - An iterable yielding (train, test) splits as arrays of indices.\n",
      "        \n",
      "            For int/None inputs, if the estimator is a classifier and ``y`` is\n",
      "            either binary or multiclass, :class:`StratifiedKFold` is used. In all\n",
      "            other cases, :class:`KFold` is used.\n",
      "        \n",
      "            Refer :ref:`User Guide <cross_validation>` for the various\n",
      "            cross-validation strategies that can be used here.\n",
      "        \n",
      "            .. versionchanged:: 0.22\n",
      "                ``cv`` default value if None changed from 3-fold to 5-fold.\n",
      "        \n",
      "        scoring : str or callable, default=None\n",
      "            A str (see model evaluation documentation) or\n",
      "            a scorer callable object / function with signature\n",
      "            ``scorer(estimator, X, y)``.\n",
      "        \n",
      "        n_jobs : int, default=None\n",
      "            Number of jobs to run in parallel.\n",
      "            ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      "            ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      "            for more details.\n",
      "        \n",
      "        pre_dispatch : int or str, default='all'\n",
      "            Number of predispatched jobs for parallel execution (default is\n",
      "            all). The option can reduce the allocated memory. The str can\n",
      "            be an expression like '2*n_jobs'.\n",
      "        \n",
      "        verbose : int, default=0\n",
      "            Controls the verbosity: the higher, the more messages.\n",
      "        \n",
      "        error_score : 'raise' or numeric, default=np.nan\n",
      "            Value to assign to the score if an error occurs in estimator fitting.\n",
      "            If set to 'raise', the error is raised.\n",
      "            If a numeric value is given, FitFailedWarning is raised. This parameter\n",
      "            does not affect the refit step, which will always raise the error.\n",
      "        \n",
      "            .. versionadded:: 0.20\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        train_scores : array of shape (n_ticks, n_cv_folds)\n",
      "            Scores on training sets.\n",
      "        \n",
      "        test_scores : array of shape (n_ticks, n_cv_folds)\n",
      "            Scores on test set.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        See :ref:`sphx_glr_auto_examples_model_selection_plot_validation_curve.py`\n",
      "\n",
      "DATA\n",
      "    __all__ = ('BaseCrossValidator', 'GridSearchCV', 'TimeSeriesSplit', 'K...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\priya\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
